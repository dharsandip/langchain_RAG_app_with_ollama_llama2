This is a Generative AI project for building a Streamlit application for extracting answers of various queries from some pdf document like medical document. For this project Langchain framework, RAG (Retrieval-Augmented Generation), Open source LLM llama2 model with Ollama tool, Hugging Face Instruct Embeddings, Chroma (open-source vector database), PyPDFLoader etc. are used. Following are the steps: 1. First pdf file is uploaded 2. Then it is splitted into chunks of text data 3. It is converted into vector representation (by transforming data into embeddings). 4. The user query is also converted into an embedding and the system compares the query embedding with the stored document embeddings in vectorstore using similarity search. It then identifies and retrieves the chunks whose embeddings are most similar to the query embedding. 5. The retrieved text chunks along with the user query are fed into LLM (in our case it is Open source Llama2 model). Then it generates a suitable response to the userâ€™s query. In the App, user just needs to upload the pdf file and also type the Query and then just click on the "Query Document" button. It will display the extracted answer/information. The App has been thoroughly tested with a sample medical document and all the queries about the patient have been answered correctly.